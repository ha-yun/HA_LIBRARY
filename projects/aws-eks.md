<details>
<summary>ì´ˆê¸° ë¡œì»¬ ì„¸íŒ…</summary>

1. AWS CLI ì„¤ì¹˜
  - AWS Command Line Interface(AWS CLI)ëŠ” AWS ì„œë¹„ìŠ¤ë¥¼ ê´€ë¦¬í•˜ëŠ” í†µí•© ë„êµ¬, ë„êµ¬ í•˜ë‚˜ë§Œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ êµ¬ì„±í•˜ë©´ ì—¬ëŸ¬ AWS ì„œë¹„ìŠ¤ë¥¼ ëª…ë ¹ì¤„ì—ì„œ ì œì–´í•˜ê³  ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ìë™í™” ê°€ëŠ¥
2. kubectl & eksctl ì„¤ì¹˜
  - https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/install-kubectl.html
      - ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ëª…ë ¹ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì»¤ë§¨ë“œ ë¼ì¸ ë„êµ¬
  - https://eksctl.io/installation/
      - Amazon EKSì—ì„œ Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„± ë° ê´€ë¦¬í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ ëª…ë ¹ì¤„ ìœ í‹¸ë¦¬í‹°ì¸ eksctl
3. aws-cliì—ì„œ aws ê³„ì • ì—°ê²°
  - https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/what-is-eks.html
  - aws cliì—ì„œ íŠ¹ì • ì‚¬ìš©ìë¡œ ë¡œê·¸ì¸í•˜ëŠ” ë°©ë²•
      
    ```markdown
    1. ë¨¼ì € IAMì—ì„œ ê° ê³„ì •ì—ì„œ access keyë¥¼ ìƒì„±í•´ì•¼ í•¨(ìƒì„±í•˜ë©´ cvs íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆìŒ)
    2. `aws configure` ëª…ë ¹ìœ¼ë¡œ ì•„ë˜ í•­ëª©ë“¤ì„ ì„¤ì •í•œë‹¤. access key ë°œê¸‰ ë°›ìœ¼ê±°ë¥¼ ì•„ë˜ì™€ ê°™ì´ ì…ë ¥í•˜ë©´ ë¨
        AWS Access Key ID [****************6LW5]: A
        AWS Secret Access Key [****************JEwz]: t
        Default region name: [us-east-1]
        Default output format: [json]
        
    3. `aws configure list`ë¡œ ì •ë³´ í™•ì¸
    ```

</details>

<details>
<summary>EKS êµ¬ì„±</summary>

1. EKS êµ¬ì„±(í´ëŸ¬ìŠ¤í„° ìƒì„±)
```
eksctl create cluster --name hyeon-cluster --region us-east-1 --without-nodegroup
# ë²„ì „ëª…ì‹œ
eksctl create cluster --name í´ëŸ¬ìŠ¤í„° ì´ë¦„ --region ì‚¬ìš© ë¦¬ì „ --version ë²„ì „ (ì„ íƒ) --without-nodegroup
```

2. eksctlì—ì„œ eks ì¡°ì‘ì„ ìœ„í•´ context ìƒì„± : eksctlë¡œ ìƒì„±í•œ ê²½ìš° contextê°€ ìë™ìœ¼ë¡œ ì¶”ê°€ë¨
`aws eks update-kubeconfig --region ì‚¬ìš© ë¦¬ì „ --name ì‚¬ìš©í•  í´ëŸ¬ìŠ¤í„° ì´ë¦„`
    - í˜„ì¬ context í™•ì¸ ì½”ë“œ
     `kubectl config current-context`

    - aws eks update-kubeconfig(ë¯¸ë‹ˆíë¸Œì¼ ë–„)
      - í˜„ì¬ ì‹œìŠ¤í…œì˜ Kubernetes ì„¤ì • íŒŒì¼ (~/.kube/config) ì„ ì—…ë°ì´íŠ¸í•´ì„œ, í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— kubectlì´ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•¨.


3. EKS node group ìƒì„±(aws ì½˜ì†”)
    ```markdown
    IAM role ìƒì„± (AmazonEKSNodeRole) -> ì½˜ì†”ì—ì„œ GUIë¡œ ì¶”ê°€ ê°€ëŠ¥
                - AmazonEKSWorkerNodePolicy
                - AmazonEC2ContainerRegistryReadOnly
                - AmazonEKSServicePolicy
                - AmazonEKS_CNI_Policy
    -> IAM ì—­í• ì—ì„œ AmazonEKSNodeRole í•´ë‹¹ ì—­í• ì— ìœ„ì˜ ì •ì±…ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
    ```
    - eksctlë¡œë„ node group ìƒì„± ê°€ëŠ¥(ë¹„ì¶”ì²œ)
        
        ```
          eksctl create nodegroup \
              --cluster clusterì´ë¦„ \
              --name nodegroupì´ë¦„\
              --node-type t3.medium \
              --nodes 2 \
              --nodes-min 1 \
              --nodes-max 3 \
              --managed \
              --region ë¦¬ì „ëª…
        ```
        
4. EFS CSI ë“œë¼ì´ë²„ ì„¤ì¹˜
    - ì½˜ì†”
        - EKS â†’ ì¶”ê°€ ê¸°ëŠ¥ â†’ ì¶”ê°€ ê¸°ëŠ¥ ê°€ì ¸ì˜¤ê¸° â†’  EFS CSI ë“œë¼ì´ë²„ ì„ íƒ í›„ ìƒì„±
    - eksctl ê°€ëŠ¥ì€ í•¨
        ```
        ## CSI ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ì„¤ì¹˜ í•„ìš”í•¨
        kubectl get csidrivers
        helm repo add aws-efs-csi-driver https://kubernetes-sigs.github.io/aws-efs-csi-driver/
        helm repo update
        helm upgrade --install aws-efs-csi-driver aws-efs-csi-driver/aws-efs-csi-driver \
          --namespace kube-system \
          --set image.repository=602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/aws-efs-csi-driver
        kubectl get pods -n kube-system | grep efs
        ```
        
5. ECR(Container Registry) ìƒì„± & ì´ë¯¸ì§€ push : [615299753054.dkr.ecr.ap-northeast-2.amazonaws.com](http://615299753054.dkr.ecr.ap-northeast-2.amazonaws.com/)
    - push ë°©ë²•
        1. **AWS ECR(Amazon Elastic Container Registry)** ì— **Dockerë¡œ ë¡œê·¸ì¸ â†’ AWSì— ìˆëŠ” Docker ì´ë¯¸ì§€ ì €ì¥ì†Œì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ ì¸ì¦í•˜ëŠ” ê³¼ì •**
            
            `aws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin [777205220558.dkr.ecr.ap-northeast-2.amazonaws.com](http://777205220558.dkr.ecr.ap-northeast-2.amazonaws.com/)`
            
            â‡’ ê²°ê³¼ : ë¡œê·¸ì¸ ì„±ê³µ 
            
            - ì£¼ìš” í¬ì¸íŠ¸
                - `-username`ì€ ë¬´ì¡°ê±´ `AWS` (ê³ ì •ê°’)
                - `-password-stdin`ìœ¼ë¡œ í† í°ì„ stdinìœ¼ë¡œ ë°›ìŒ (ë³´ì•ˆìƒ ì•ˆì „)
        2. ë„ì»¤ì— ì´ë¯¸ì§€ ìƒì„±
            
            `docker tag {develop/dsp-svc-control:latest} [777205220558.dkr.ecr.ap-northeast-2.amazonaws.com/{develop/dsp-svc-control:latest}](http://777205220558.dkr.ecr.ap-northeast-2.amazonaws.com/%7Bdevelop/dsp-svc-control:latest%7D)`
            
        3. ì´ë¯¸ì§€ í‘¸ì‹œ
            - ì£¼ì˜ : repositoryë¥¼ ë¯¸ë¦¬ ë§Œë“¤ì–´ ë‘¬ì•¼ ì´ë¯¸ì§€ pushê°€ ê°€ëŠ¥í•¨  ex) "develop/dsp-svc-controlâ€
            
            `docker push [615299753054.dkr.ecr.ap-northeast-2.amazonaws.com/{develop/dsp-svc-control:latest}](http://615299753054.dkr.ecr.ap-northeast-2.amazonaws.com/%7Bdevelop/dsp-svc-control:latest%7D)`
            
6. EFS ìƒì„±
    > EFS ì™€ PVC ì„¤ì • ë¶€ë¶„ì„ ìë™í™” ì§„í–‰ ì½”ë“œ ì¡´ì¬(íŒŒì´ì¬)
    ì•„ë˜ìª½ â€œEFS ì„¸íŒ… ë° PVCâ€ ë¶€ë¶„ ì°¸ê³ 
    > 
    - aws ì½˜ì†”ì—ì„œ efs ìƒì„±
    - ìƒì„± í›„, EFSì— access point ì„¤ì • í•„ìš” : EFS Acces Point ìƒì„±ì •ë³´.yaml ì°¸ì¡°
        - `kubectl apply -f createpv.yaml` (ì˜ˆì‹œ)
            
            ```
            apiVersion: v1
            kind: PersistentVolume
            metadata:
              name: streamsets-data-pv
              labels:
                type: streamsets-data-pv
            spec:
              capacity:
                storage: 1Gi
              volumeMode: Filesystem
              accessModes:
                - ReadWriteMany
              persistentVolumeReclaimPolicy: Retain
              storageClassName: efs-sc
              csi:
                driver: efs.csi.aws.com
                volumeHandle: efsì•„ì´ë””:: Ecrí•´ë‹¹ì´ë¯¸ì§€url
            ```
            
        
7. EFS ë„¤íŠ¸ì›Œí¬ > ê´€ë¦¬ > eks clusterì˜ ë³´ì•ˆê·¸ë£¹ì„ ì¶”ê°€í•´ì¤€ë‹¤.
    - VPC: ì‚¬ìš©ì¤‘ì¸ í´ëŸ¬ìŠ¤í„°ì˜ VPC
        - í•´ë‹¹ VPCì—ì„œ ì‚¬ìš©ì¤‘ì¸ ì„œë¸Œë„· í™•ì¸ í•„ìš” (a~d)
    - íƒ‘ì¬ëŒ€ìƒ ì¶”ê°€
        - ì‚¬ìš©ì¤‘ì¸ ê°€ìš© ì˜ì—­ ëª¨ë‘ ì¶”ê°€
        - ì„œë¸Œë„· ID: EC2ì—ì„œ ê° ì¸ìŠ¤í„´ìŠ¤ì˜ ì„œë¸Œë„·ID í™•ì¸í•˜ì—¬ ë™ì¼í•œ ID ì¶”ê°€
        - IP ì£¼ì†Œ: ê³µë°±
        - ë³´ì•ˆê·¸ë£¹: ì‚¬ìš©ì¤‘ì¸ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ë“¤ì–´ê°„ ë³´ì•ˆê·¸ë£¹ë“¤ ëª¨ë‘ ì¶”ê°€
8. PersistentVolumeClaim ìƒì„±
    
    `kubectl apply -f 0.storageClass.yaml`
    
    `kubectl apply -f 1.createpv.yaml`
    
    - createpv ì ìš© ì‹œ í™•ì¸
        - ê° ì—‘ì„¸ìŠ¤ í¬ì¸íŠ¸ idê°€ ì•Œë§ê²Œ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸
9. node label ì‘ì—…
    - node ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        `kubectl get node`
        
    
    ```
    kubectl label nodes {eks ë…¸ë“œ1 id} dspESType=master
    kubectl label nodes {eks ë…¸ë“œ1 id} dspSparkType=master
    
    kubectl label nodes {eks ë…¸ë“œ2 id} dspESType=data1
    kubectl label nodes {eks ë…¸ë“œ2 id} dspSparkType=worker
    
    kubectl label nodes {eks ë…¸ë“œ3 id} dspESType=data2
    kubectl label nodes {eks ë…¸ë“œ3 id} dspSparkType=worker
    kubectl label nodes {eks ë…¸ë“œ3 id} dspDBType=postgre
    ```
    
    - node label ì˜ ë¶™ì—ˆëŠ”ì§€ í™•ì¸
    
            `kubectl get nodes --show-labels`

</details>  

<details>
<summary> ì¸í”„ë¼ ì„¤ì¹˜</summary>

- ConfigMap
    1. ConfigMap ì„¤ì • ì¶”ê°€í•˜ê¸°
        
        `kubectl apply -f [configMap.yaml]`
        
    2. ConfigMap ì •ë³´ í™•ì¸í•˜ê¸°
        
        `kubectl get configmap`
            
    
- ALB(AWS-LoadBalancer)ë¥¼ ì‚¬ìš©í•œ ingressêµ¬í˜„
    1.  **OIDC ê³µê¸‰ìì™€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ -> URLì´ ì¶œë ¥ë˜ë©´ ì—°ê²°ë˜ì–´ ìˆëŠ”ê±°!**
        
        `aws eks describe-cluster --name {í´ëŸ¬ìŠ¤í„°ì´ë¦„} --query "cluster.identity.oidc.issuer" --output text`
        
        - **OIDCê°€ ë­ì§€?**
            - OpenID Connectì˜ ì¤„ì„ë§ë¡œ, í˜„ëŒ€ì ì¸ ì¸ì¦(Authentication)ê³¼ ì‚¬ìš©ì ì •ë³´ í™•ì¸(Identity)ì„ ë‹¤ë£¨ëŠ” í‘œì¤€ í”„ë¡œí† ì½œ
                - oauth 2.0 ê¸°ë°˜ í”„ë¡œí† ì½œ -> eksë“¤ì´ efsë“±ì˜ awsì„œë¹„ìŠ¤ ì ‘ê·¼ ê¶Œí•œ ê°€ì§ˆ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤Œ
    2. **IAM ì„¤ì • + OIDC Provider ì—°ê²° / eks ì™¸ë¶€ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì¸ì¦ ê¸°ë°˜ ìƒì„±**
        
        `eksctl utils associate-iam-oidc-provider --region {ë¦¬ì „ëª…} --cluster {í´ëŸ¬ìŠ¤í„°ì´ë¦„} --approve`
        
    3. **IAM ì •ì±… íŒŒì¼ ë‹¤ìš´ë¡œë“œ, ì €ì¥**
        
        `curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.3.1/docs/install/iam_policy.json`
        
    4. **bì—ì„œ ë‹¤ìš´ë°›ì€  json íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ IAM ì •ì±… ìƒì„±**
        
        `aws iam create-policy \
        --policy-name AWSLoadBalancerControllerIAMPolicy \
        --policy-document file://iam_policy.json`
        
    5. **EKSì—ì„œ IRSA ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ aws-load-balancer-controller AWS ë¦¬ì†ŒìŠ¤ë¥¼ ê¶Œí•œìˆê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ IAM ì—­í•  ì—°ê²° -> dì—ì„œ ë§Œë“  IAM ì •ì±…ì„ ë‚´ í´ëŸ¬ìŠ¤í„°ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡  ì—°ê²°**
        
        `eksctl create iamserviceaccount \
        --cluster={í´ëŸ¬ìŠ¤í„°ì´ë¦„} \
        --namespace=kube-system \
        --name=aws-load-balancer-controller \
        --attach-policy-arn=arn:aws:iam::777205220558:policy/AWSLoadBalancerControllerIAMPolicy \
        --override-existing-serviceaccounts \
        --region {ë¦¬ì „ëª…} \
        --approve`
        
    6. **ALB Ingress Controller ì„¤ì¹˜ & ì‹¤í–‰ (Helm)**
        
        `helm repo add eks https://aws.github.io/eks-charts
        helm repo update`
        
        `helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
        -n kube-system \
        --set clusterName={í´ëŸ¬ìŠ¤í„°ì´ë¦„} \
        --set serviceAccount.create=false \
        --set serviceAccount.name=aws-load-balancer-controller` 
        
    7.  **ALB ì»¨íŠ¸ë¡¤ëŸ¬ê°€ ì˜ ë°°í¬ë˜ì—ˆëŠ”ì§€ í™•ì¸**
        
          `kubectl get deployment -n kube-system aws-load-balancer-controller`
        
    
    - **ingress ì ‘ì†(ë¡œì»¬ì—ì„œë§Œ í•œë‹¤ë©´)**
        - Ingress ip ì°¾ê¸°
        `dig +short k8s-default-demo1ing-c691c37f5b-1078457141.ap-northeast-2.elb.amazonaws.com`
        - ë¡œì»¬  `sudo vi /etc/hosts`
            
            â‡’ íŒŒì¼ì— Ingress IPë‘ Hostnameì„ ì¶”ê°€í•œ ì´ìœ ëŠ” ë°”ë¡œ **ë„ë©”ì¸ ì´ë¦„ìœ¼ë¡œ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•˜ê¸° ìœ„í•´ì„œ**
            
            - vi ì‹¤í–‰ ì‹œ â†’ ië¥¼ ëˆ„ë¥´ë©´ Insertë¡œ ì§„ì…, ë§¨ ë§ˆì§€ë§‰ ì¤„ì—
                
                ```perl
                `<INGRESS-IP>  HOSTSì´ë¦„(demo1.sumits.cloud,kafkamanager.sumits.cloud,streamsets.sumits.cloud)`
                ```
                
                ì¶”ê°€ í›„ esc > :wq ì €ì¥
                
            - `curl <http://demo1.sumits.cloud`ë¡œ í™•ì¸ í›„ ì ‘ì†
    
    - [**Route53](https://us-east-1.console.aws.amazon.com/route53/v2/home?region=us-east-1)**
        
        AmazonÂ ***Route 53***ëŠ” ê°€ìš©ì„±ê³¼ í™•ì¥ì„±ì´ ë›°ì–´ë‚œ ë„ë©”ì¸ ì´ë¦„ ì‹œìŠ¤í…œ(DNS) ì›¹ ì„œë¹„ìŠ¤
        
        1. Route53ì— â€œí˜¸ìŠ¤íŒ… ì˜ì—­â€ ì´ë™
        2. â€œ[seoultravel.life](https://us-east-1.console.aws.amazon.com/route53/v2/hostedzones?region=us-east-1#/ListRecordSets/Z01234593VVAOVTHSBEQA)â€ í´ë¦­ ì§„í–‰
        3. ë ˆì½”ë“œ ìƒì„± í´ë¦­
            
            ![image.png](attachment:fa80bd7d-2d97-479e-820d-7ffdbe3e3958:image.png)
            
        4. ì•„ë˜ ì‚¬ì§„ê³¼ ê°™ì´ ì„¸íŒ…
            
            ![image.png](attachment:02882dfc-ed8a-4bd1-bd05-58bd1af45832:image.png)
            
            - ë ˆì½”ë“œ ì´ë¦„ì€ â€œë“¤ì–´ê°ˆ ì›¹ì‚¬ì´íŠ¸ ì„¤ì •â€
            - ë ˆì½”ë“œ ìœ í˜• CNAME (ë””í´íŠ¸ëŠ” Aë ˆì½”ë“œ, Aë ˆì½”ë“œëŠ” IPì£¼ì†Œë¡œ ì…ë ¥í•´ì•¼í•¨)
            - ê°’ì€ `kubectl get ingress` ë‚˜ì˜¨ ADDRESSë¥¼ ì…ë ¥í•´ì•¼í•¨

- racher
    1. helmì— racher ì„¤ì¹˜í•˜ê¸° ìœ„í•œ í´ë”ë¥¼ ì¶”ê°€
    `helm repo add rancher-latest https://releases.rancher.com/server-charts/latest`
    2. eksì— racher ì„¤ì¹˜í•  namespace ìƒì„±
    `kubectl create namespace cattle-system`
    3. eksì— racher ì„¤ì¹˜
    `helm install rancher rancher-latest/rancher --namespace cattle-system --set replicas=1 --set bootstrapPassword=admin --set ingress.tls.source=secret`
    4. racherìš© loadbalancer ìƒì„±
    `kubectl apply -f 0.rancher_lb.yaml`
        - kubectl get svc -A ë¡œ lbì˜ ì™¸ë¶€ IP í™•ì¸
            - https://ì™¸ë¶€IPë¡œ racher ì ‘ì†
    5. ë¹„ë°€ë²ˆí˜¸ í™•ì¸(ì´ˆê¸° íŒ¨ìŠ¤ì›Œë“œ í™•ì¸ ë²• â†’ admin ì•ˆë ë–„)
        - kubectl get pods -A â†’ racher pod ì´ë¦„ í™•ì¸
        
          `kubectl logs -n cattle-system ë˜ì²˜ pod ì´ë¦„ | grep "Bootstrap Password:â€`
        
    6. ë¹„ë°€ë²ˆí˜¸ ì´ˆê¸°í™”(ì•ˆë  ì‹œ)
        
        `kubectl -n cattle-system exec -it ë˜ì²˜ pod ì´ë¦„ -- reset-password`
            
- Volumemount
    
    <aside>
    ğŸ’¡
    > ì•„ë˜ ì½”ë“œì˜ ê²½ë¡œëŠ” Final_project\yml\infra ì—ì„œ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.
    ì´ 4ê°œì˜ ë³¼ë¥¨ë§ˆìš´íŠ¸ë¥¼ ì„¤ì •í•´ì•¼ í•œë‹¤
    > 
    </aside>
    
    ### kibana
    
    1. yaml  íŒŒì¼ ìˆ˜ì •
        
        ```yaml
        # 1.demo1.yaml íŒŒì¼ì—ì•„ë˜ ë‚´ìš© ì¶”ê°€
        # ê¸°ë³¸ì ìœ¼ë¡œ ì—†ì„ê²½ìš° ë§Œë“¤ê³ , ë°›ì€ ì½”ë“œì—ëŠ” ë¶™ì–´ìˆìŒ
        spec:
          template:
            spec:
              containers:
                volumeMounts:
                  - name: kibana-config
                    mountPath: /usr/share/kibana/config
                volumes:
                  - name: kibana-config
                    persistentVolumeClaim:
                      claimName: kibana-config-pvc
        ```
        
    2.  ë°°í¬ë¥¼ í†µí•´ PVCë¥¼ ë³¼ë¥¨ë§ˆìš´íŠ¸ë¥¼ ì—°ê²°í•œë‹¤
        
        `kubectl apply -f 1.demo1.yaml`
        
    3. cp ëª…ë ¹ì–´ë¥¼ í†µí•´ ë³µì‚¬í•˜ê¸°
        
        `kubectl cp volumemount\kibana\config\. [demo1-podì´ë¦„]:/usr/share/kibana/config/kibana.yml` 
        
    
    ### es-data-1
    
    1. yaml  íŒŒì¼ ìˆ˜ì •
        
        ```yaml
        # 1.demo1.yaml íŒŒì¼ì—ì•„ë˜ ë‚´ìš© ì¶”ê°€
        # ê¸°ë³¸ì ìœ¼ë¡œ ì—†ì„ê²½ìš° ë§Œë“¤ê³ , ë°›ì€ ì½”ë“œì—ëŠ” ë¶™ì–´ìˆìŒ
        spec:
          template:
            spec:
              containers:
                volumeMounts:
                  - name: es-data1-config
                    mountPath: /usr/share/data1/config
                volumes:
                  - name: es-data1-config
                    persistentVolumeClaim:
                      claimName: es-data1-config-pvc
        ```
        
    2.  ë°°í¬ë¥¼ í†µí•´ PVCë¥¼ ë³¼ë¥¨ë§ˆìš´íŠ¸ë¥¼ ì—°ê²°í•œë‹¤
        
        `kubectl apply -f 1.demo1.yaml`
        
    3. cp ëª…ë ¹ì–´ë¥¼ í†µí•´ ë³µì‚¬í•˜ê¸°
        
        `kubectl cp volumemount\es-data-7.10.0-oss\config\. [demo1-podì´ë¦„]:/usr/share/data1/config/`
        
    
    ### es-data-2
    
    1. yaml  íŒŒì¼ ìˆ˜ì •
        
        ```yaml
        # 1.demo1.yaml íŒŒì¼ì—ì•„ë˜ ë‚´ìš© ì¶”ê°€
        # ê¸°ë³¸ì ìœ¼ë¡œ ì—†ì„ê²½ìš° ë§Œë“¤ê³ , ë°›ì€ ì½”ë“œì—ëŠ” ë¶™ì–´ìˆìŒ
        spec:
          template:
            spec:
              containers:
                volumeMounts:
                  - name: es-data2-config
                    mountPath: /usr/share/data2/config
                volumes:
                  - name: es-data2-config
                    persistentVolumeClaim:
                      claimName: es-data2-config-pvc
        ```
        
    2.  ë°°í¬ë¥¼ í†µí•´ PVCë¥¼ ë³¼ë¥¨ë§ˆìš´íŠ¸ë¥¼ ì—°ê²°í•œë‹¤
        
        `kubectl apply -f 1.demo1.yaml`
        
    3. cp ëª…ë ¹ì–´ë¥¼ í†µí•´ ë³µì‚¬í•˜ê¸°
        
        `kubectl cp volumemount\es-data-7.10.0-oss\config\. [demo1-podì´ë¦„]:/usr/share/data1/config/`
        
    
    ### es-master
    
    1. yaml  íŒŒì¼ ìˆ˜ì •
        
        ```yaml
        # 1.demo1.yaml íŒŒì¼ì—ì•„ë˜ ë‚´ìš© ì¶”ê°€
        # ê¸°ë³¸ì ìœ¼ë¡œ ì—†ì„ê²½ìš° ë§Œë“¤ê³ , ë°›ì€ ì½”ë“œì—ëŠ” ë¶™ì–´ìˆìŒ
        spec:
          template:
            spec:
              containers:
                volumeMounts:
                  - name: es-master-config
                    mountPath: /usr/share/master/config
                volumes:
                  - name: es-master-config
                    persistentVolumeClaim:
                      claimName: es-master-config-pvc
        ```
        
    2.  ë°°í¬ë¥¼ í†µí•´ PVCë¥¼ ë³¼ë¥¨ë§ˆìš´íŠ¸ë¥¼ ì—°ê²°í•œë‹¤
        
        `kubectl apply -f 1.demo1.yaml`
        
    3. cp ëª…ë ¹ì–´ë¥¼ í†µí•´ ë³µì‚¬í•˜ê¸°
        
        `kubectl cp volumemount\es-master-7.10.0-oss\config\. [demo1-podì´ë¦„]:/usr/share/master/config/`
        
    
    ```yaml
    # 4ê°œì˜ ë³¼ë¥¨ë§ˆìš´íŠ¸ë¥¼ ì„¤ì •í•˜ë©´ ì•„ë˜ì™€ ê°™ìŒ 
    spec:
      ...
      template:
        ...
        spec:
          ...
            volumeMounts: # volumesì—ì„œ ì„¤ì •í•œ pvcë¥¼ ì‹¤ì œ í´ë”ë¡œ ì—°ê²°
            ...
            - name: kibana-config # volumesì—ì„œ ì„¤ì •í•œ pvc ì´ë¦„
              mountPath: /usr/share/kibana/config # ì‹¤ì œ podë‚´ ë§ˆìš´íŠ¸(ì—°ë™) ëœ ê²½ë¡œ 
            - name: es-master-config
              mountPath: /usr/share/master/config
            - name: es-data1-config
              mountPath: /usr/share/data1/config
            - name: es-data2-config
              mountPath: /usr/share/data2b/config 
          volumes: # ì‹¤ì œ pvcë¥¼ í•´ë‹¹ podì— ì—°ê²°í•´ì£¼ëŠ” ì½”ë“œ
            ...
            - name: kibana-config # ì´ëŸ¬í•œ ì´ë¦„ìœ¼ë¡œ pvcë¥¼ podì—ì„œ ì‚¬ìš©
              persistentVolumeClaim: # ì‚¬ìš©í•  pvc ì´ë¦„
                claimName: kibana-config-pvc
            - name: es-master-config
              persistentVolumeClaim:
                claimName: es-master-config-pvc
            - name: es-data1-config
              persistentVolumeClaim:
                claimName: es-data1-config-pvc
            - name: es-data2-config
              persistentVolumeClaim:
                claimName: es-data2-config-pvc
    ```
    - ìš”ì•½
      1. demo1 í¬ë“œê°€ kibana-config PVCë¥¼ ë§ˆìš´íŠ¸ -> ì¦‰, demo1 í¬ë“œ ì•ˆì˜ /usr/share/kibana/config ê²½ë¡œëŠ” ì‚¬ì‹¤ PVCë¡œ ì—°ê²°ëœ "ì™¸ë¶€ ë””ìŠ¤í¬"ë¼ê³  ë³´ë©´ ë¨.
      2. kubectl cpë¡œ demo1 í¬ë“œì— íŒŒì¼ì„ ë³µì‚¬ -> PVC ë””ìŠ¤í¬ ì•ˆìœ¼ë¡œ kibana.yml íŒŒì¼ì´ ì €ì¥(/usr/share/kibana/configê°€ PVCì™€ ì—°ê²°ë¼ ìˆì—ˆê¸° ë•Œë¬¸ì—)
        - demo1 í¬ë“œ = PVCì— íŒŒì¼ì„ ë„£ëŠ” ìš©ë„ (íŒŒì¼ì„ "ì—…ë¡œë“œ"í•˜ëŠ” í†µë¡œ)
      3. ì´ì œ ì´ Kibana Podë„ /usr/share/kibana/configì—ì„œ PVCì— ì €ì¥ëœ kibana.ymlì„ ì½ì„ ìˆ˜ ìˆê²Œ ë¨.


- PostgreSQL
    - `kubectl apply -f 1.postgresql.yaml`
        
        ```perl
        apiVersion: v1
        kind: ReplicationController
        metadata:
          name: postgresql
        spec:
          replicas: 1
          template:
            metadata:
              labels:
                app: postgresql
            spec:
              containers:
              - name: postgresql
                image: 777205220558.dkr.ecr.ap-northeast-2.amazonaws.com/postgres:10.13-alpine
                env:
                  - name: POSTGRES_USER
                    value: postgres
                  - name: POSTGRES_PASSWORD
                    value: "example"
                  - name: POSTGRES_DB
                    value: postgres
                  - name: PGDATA
                    value: /var/lib/postgresql/data
                  - name: TZ
                    value: Asia/Seoul
                ports:
                  - containerPort: 5432
                volumeMounts:
                  - name: postgres
                    mountPath: /var/lib/postgresql/data
        #          - name: timezone
        #            mountPath: /etc/localtime
        #            readOnly: true
              volumes:
                - name: postgres
                  persistentVolumeClaim:
                    claimName: postgre-data-pvc
        #        - hostPath:
        #            path: /etc/localtime
        #          name: timezone
              nodeSelector:
                dspDBType : "postgre"
        ---
        apiVersion: v1
        kind: Service
        metadata:
          labels:
            component: postgres
          name: postgres-cs
        spec:
          ports:
            - port: 5432
              targetPort: 5432
              protocol: TCP
              name: pgql
          selector:
            app: postgresql
          type: ClusterIP
        ```
        
    - `kubectl apply -f 2.postgresql_lb.yaml`
        
        ```perl
        ---
        apiVersion: v1
        kind: Service
        metadata:
          labels:
            component: postgres
          name: postgres-lb
        annotations:
          service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
        spec:
          ports:
            - port: 5432
              targetPort: 5432
              protocol: TCP
              name: pgql
          selector:
            app: postgresql
          type: LoadBalancer
        ```
        
        - https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.2/guide/service/annotations/#lb-scheme
            
            `annotations:
              service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing`
            
            - ì´ê±°ë¥¼ ì¶”ê°€í•´ì•¼ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ê°€ëŠ¥
                - `service.beta.kubernetes.io/aws-load-balancer-scheme`NLBê°€ ì¸í„°ë„·ì— ì—°ê²°ë˜ëŠ”ì§€, ë‚´ë¶€ì— ì—°ê²°ë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ìœ íš¨í•œ ê°’ì€Â `internal`, ì…ë‹ˆë‹¤Â `internet-facing`. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì€ ì…ë‹ˆë‹¤Â `internal`.
    - init.txt íŒŒì¼ë‚´ ì‹¤í–‰
        
        ```perl
        kubectl exec -it {postgresqlì´ë¦„} -- mkdir /var/lib/postgresql/data ;sleep 5;
        kubectl exec -it {postgresqlì´ë¦„} -- mkdir /var/lib/postgresql/data/ts_temp ;sleep 5;
        kubectl exec -it {postgresqlì´ë¦„} -- chown -R postgres:postgres /var/lib/postgresql/data/ ;sleep 5;
        kubectl cp init.sql {postgresqlì´ë¦„}:/
        kubectl exec -it {postgresqlì´ë¦„} -- psql -U postgres -f "/init.sql" ;sleep 15;\
        kubectl exec -it {postgresqlì´ë¦„} -- psql -U postgres -c "DROP SCHEMA secuiot" ;sleep 5;\
        kubectl exec -it {postgresqlì´ë¦„} -- sh -c "export PGPASSWORD=secuiot1q2w" ;sleep 5;\
        kubectl exec -it {postgresqlì´ë¦„} -- psql secuiot -U secuiot -c "CREATE SCHEMA secuiot AUTHORIZATION secuiot"
        ```
        
        - init.sql íŒŒì¼ ê°™ì€ ê³µê°„ì— í•„ìš”
            
            ```perl
            -- ì‚¬ìš©ì ìƒì„±
            CREATE USER secuiot WITH PASSWORD 'secuiot1q2w';
            
            -- ë¦¬ëˆ…ìŠ¤ì—ì„œ ì‚¬ìš©
            CREATE TABLESPACE ts_temp OWNER secuiot location '/var/lib/postgresql/data/ts_temp';
            
            ------------------------------------------------------------------------------------
            --ì‚¬ìš©ì default_tablespace ì„¤ì •
            ------------------------------------------------------------------------------------
            ALTER ROLE secuiot SET DEFAULT_TABLESPACE TO ts_temp;
            
            ------------------------------------------------------------------------------------
            --database ìƒì„± ë° default_tablespace ì„¤ì •
            ------------------------------------------------------------------------------------
            CREATE DATABASE secuiot OWNER secuiot;
            
            ALTER DATABASE secuiot SET DEFAULT_TABLESPACE to ts_temp;
            
            --connect secuiot secuiot
            --------------------------------------------------------------------------------------------------------------
            -- DBë¥¼ secuiotë¡œ ì¬ì ‘ì†í•œë‹¤
            -- 0.ì‹¤í–‰ : secuiot(DB) secuiot(sechema) secuiot(ê³„ì •)
            --------------------------------------------------------------------------------------------------------------
            CREATE SCHEMA secuiot AUTHORIZATION secuiot;
            
            ```
                
        
- kibanaë€?
    
    Elasticsearchì˜ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆëŠ” ëŒ€ì‹œë³´ë“œ ë„êµ¬
    
    - Elasticsearchì— ì €ì¥ëœ **ë¡œê·¸, ë©”íŠ¸ë¦­, íŠ¸ë ˆì´ìŠ¤ ë°ì´í„°ë¥¼** ğŸ‘‰ **ì°¨íŠ¸, ê·¸ë˜í”„, ëŒ€ì‹œë³´ë“œ**ë¡œ ì‹œê°í™”í•´ì¤Œ
    - **ê²€ìƒ‰ + í•„í„°ë§**ìœ¼ë¡œ ì›í•˜ëŠ” ì •ë³´ ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆìŒ
    - ì‹¤ì‹œê°„ìœ¼ë¡œ ë¡œê·¸/ë°ì´í„°ë¥¼ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥

</details>       

### EFS ì„¸íŒ… ë° PVC
[makeefs2.py](attachment:4bbb8e59-1747-4756-bb6a-e7c34fc77cfe:makeefs2.py)

<aside>
ğŸ’¡ EFS Access Point ì„±ì„±ì •ë³´.yaml íŒŒì¼ê³¼ 1.createpv.yaml íŒŒì¼ì„ ê°™ì€ ê²½ë¡œë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”
***ë¦¬ì „ ì„œë²„ ì„¤ì • í•´ì£¼ì„¸ìš”*** 
</aside>

`python makeefs2.py` 
- ì‹¤í–‰ ëª…ë ¹ì–´
- cli ëª…ë ¹ì–´ ë‚˜ì—´
    - deployë¡œ ìƒì„±ëœ pod ì‚­ì œ
        
        `kubectl delete deploy postgresql`
        